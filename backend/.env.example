# WeaR Ai Backend Environment Configuration
# Copy this file to .env and fill in your values

# ===========================================
# LLM Provider Configuration
# ===========================================

# Primary Model Provider: "ollama", "vllm", "groq", "together", "openai"
LLM_PROVIDER=ollama

# Ollama Configuration (Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:70b

# vLLM Configuration (Local/Cloud)
VLLM_BASE_URL=http://localhost:8000
VLLM_MODEL=meta-llama/Llama-3.1-70B-Instruct

# Groq Configuration (Cloud - Free tier available)
GROQ_API_KEY=your-groq-api-key
GROQ_MODEL=llama-3.1-70b-versatile

# Together AI Configuration (Cloud)
TOGETHER_API_KEY=your-together-api-key
TOGETHER_MODEL=meta-llama/Llama-3.1-405B-Instruct-Turbo

# OpenAI-compatible fallback
OPENAI_API_KEY=your-openai-api-key
OPENAI_BASE_URL=https://api.openai.com/v1

# ===========================================
# Tool API Keys
# ===========================================

# Web Search (choose one)
TAVILY_API_KEY=your-tavily-api-key
SERPER_API_KEY=your-serper-api-key

# ===========================================
# Database Configuration
# ===========================================

# PostgreSQL
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/wear_ai

# Qdrant Vector Database
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

# Redis (for caching and rate limiting)
REDIS_URL=redis://localhost:6379/0

# ===========================================
# Application Settings
# ===========================================

# Server
HOST=0.0.0.0
PORT=8000
DEBUG=true

# Security
SECRET_KEY=your-super-secret-key-change-in-production
CORS_ORIGINS=["http://localhost:3000"]

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
